import streamlit as st
from google import genai
from google.genai import types

from langchain_google_genai import (
    ChatGoogleGenerativeAI,
    GoogleGenerativeAIEmbeddings,
)
from langchain_core.messages import HumanMessage, AIMessage
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS

from PIL import Image
from io import BytesIO
import base64
from streamlit_mic_recorder import mic_recorder

import fitz
import docx
import sqlite3
from datetime import datetime, timezone
import json


# ===============================
# 1. Page config
# ===============================
st.set_page_config(
    page_title="Gemini ChatGPT Style Bot + RAG",
    page_icon="ğŸ¦¦",
    layout="centered",
)
st.title("ğŸ’¬ Gemini å¤šæ¨¡æ…‹æ©Ÿå™¨äººï¼ˆRAGï¼‰")


# ===============================
# 2. Utils
# ===============================
def encode_image(img: Image.Image):
    if img.mode in ("RGBA", "LA", "P"):
        img = img.convert("RGB")
    buf = BytesIO()
    img.save(buf, format="JPEG", quality=85)
    return f"data:image/jpeg;base64,{base64.b64encode(buf.getvalue()).decode()}"


def extract_pdf(b):
    text = ""
    with fitz.open(stream=b, filetype="pdf") as d:
        for p in d:
            text += p.get_text()
    return text


def extract_docx(b):
    d = docx.Document(BytesIO(b))
    return "\n".join(p.text for p in d.paragraphs)


def build_chat_history(messages, current_human_message):
    """
    å°‡ Streamlit messages è½‰æˆ LangChain messages
    """
    chat = []
    for m in messages:
        if m["role"] == "user":
            chat.append(HumanMessage(content=m["parts"][0]))
        elif m["role"] == "assistant":
            chat.append(AIMessage(content=m["parts"][0]))

    chat.append(current_human_message)
    return chat


# ===============================
# DBï¼šæ°¸ä¹…è¨˜æ†¶ (SQLite)
# ===============================
DB_PATH = "chat_memory.db"


def init_db():
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute(
        """
        CREATE TABLE IF NOT EXISTS chat_memory (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            created_at TEXT NOT NULL,
            mode TEXT NOT NULL,
            messages_json TEXT NOT NULL
        )
        """
    )
    conn.commit()
    conn.close()


def save_memory(messages, mode):
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute(
        """
        INSERT INTO chat_memory (created_at, mode, messages_json)
        VALUES (?, ?, ?)
        """,
        (
            datetime.now(timezone.utc).isoformat(),
            mode,
            json.dumps(messages, ensure_ascii=False),
        ),
    )
    conn.commit()
    conn.close()


def load_all_memory():
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute(
        "SELECT id, created_at, mode FROM chat_memory ORDER BY id DESC"
    )
    rows = c.fetchall()
    conn.close()
    return rows


def load_memory_by_id(memory_id: int):
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute(
        "SELECT id, created_at, mode, messages_json FROM chat_memory WHERE id = ?",
        (memory_id,),
    )
    row = c.fetchone()
    conn.close()
    return row


def delete_memory_by_id(memory_id: int):
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("DELETE FROM chat_memory WHERE id = ?", (memory_id,))
    conn.commit()
    conn.close()


def delete_all_memory():
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("DELETE FROM chat_memory")
    conn.commit()
    conn.close()


# åˆå§‹åŒ– DB
init_db()


# ===============================
# 3. Session state
# ===============================
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "parts": ["ä½ å¥½ï¼å¯ä»¥ç›´æ¥æå•æˆ–ä¸Šå‚³æ•™æ ğŸ˜Š"]}
    ]

for k, v in {
    "uploaded_image": None,
    "speech_buffer": None,
    "show_image_uploader": False,
    "upload_counter": 0,
    "doc_vectorstore": None,
    "docs_loaded": False,
}.items():
    st.session_state.setdefault(k, v)


# ===============================
# 4. Gemini client / LLM / Embeddings
#    ï¼ˆä½¿ç”¨è€…å¾å‰ç«¯è²¼ API keyï¼‰
# ===============================
st.sidebar.markdown("## ğŸ”‘ API Key è¨­å®š")
api_key_input = st.sidebar.text_input(
    "è²¼ä¸Šä½ çš„ Gemini API Key",
    type="password",
)

if api_key_input:
    st.session_state["user_api_key"] = api_key_input

user_api_key = st.session_state.get("user_api_key")

if not user_api_key:
    st.sidebar.warning("è«‹å…ˆè²¼ä¸Š Gemini API Key æ‰èƒ½é–‹å§‹ä½¿ç”¨")


def setup_gemini_client(api_key: str | None):
    if not api_key:
        return None
    try:
        return genai.Client(api_key=api_key)
    except Exception as e:
        st.error(e)
        return None


def setup_llm(model_name: str, api_key: str | None):
    if not api_key:
        return None
    return ChatGoogleGenerativeAI(
        model=model_name,
        api_key=api_key,
        temperature=0.7,
    )


def setup_embeddings(api_key: str | None):
    if not api_key:
        return None
    return GoogleGenerativeAIEmbeddings(
        model="text-embedding-004",
        google_api_key=api_key,
    )


client = setup_gemini_client(user_api_key)


# ===============================
# 5. Sidebarï¼ˆæ¨¡å‹ / æª”æ¡ˆ / æ¨¡å¼ / è¨˜æ†¶ï¼‰
# ===============================
st.sidebar.markdown("## ğŸ¤– æ¨¡å‹")
MODEL_OPTIONS = {
    "Gemini 2.5 Flash": "gemini-2.5-flash",
    "Gemini 1.5": "gemini-robotics-er-1.5-preview",
}
selected_model_name = st.sidebar.selectbox("é¸æ“‡æ¨¡å‹", MODEL_OPTIONS.keys())
model_name = MODEL_OPTIONS[selected_model_name]

model = setup_llm(model_name, user_api_key)
embeddings = setup_embeddings(user_api_key)

st.sidebar.markdown("## ğŸ“š ä¸Šå‚³æª”æ¡ˆ")
rag_files = st.sidebar.file_uploader(
    "TXT / MD / PDF / DOCX",
    type=["txt", "md", "pdf", "docx"],
    accept_multiple_files=True,
)

st.sidebar.markdown("## ğŸ“ å­¸ç¿’æ¨¡å¼")
mode = st.sidebar.selectbox(
    "é¸æ“‡ä»»å‹™",
    ["ä¸€èˆ¬èŠå¤©", "è§£é‡‹/è¬›è§£", "é‡é»æ•´ç†", "å‡ºå°æ¸¬é©—"],
)

st.sidebar.markdown("## ğŸ’¾ å°è©±è¨˜æ†¶")

saved_list = load_all_memory()
if saved_list:
    options = {f"{r[0]} | {r[1][:19]} | {r[2]}": r[0] for r in saved_list}
    selected_label = st.sidebar.selectbox("å·²å„²å­˜å°è©±", list(options.keys()))
    selected_id = options[selected_label]

    c1, c2 = st.sidebar.columns(2)
    with c1:
        if st.button("è¼‰å…¥å°è©±", key="load_memory"):
            row = load_memory_by_id(selected_id)
            if row:
                _, created_at, saved_mode, messages_json = row
                st.session_state.messages = json.loads(messages_json)
                mode = saved_mode
                st.sidebar.success(f"å·²è¼‰å…¥å°è©± ID {selected_id}")
    with c2:
        if st.button("åˆªé™¤æ­¤å°è©±", key="delete_memory"):
            delete_memory_by_id(selected_id)
            st.sidebar.warning(f"å·²åˆªé™¤å°è©± ID {selected_id}")
            st.rerun()

    if st.sidebar.button("ğŸ§¨ åˆªé™¤å…¨éƒ¨è¨˜æ†¶", key="delete_all_memory"):
        delete_all_memory()
        st.sidebar.warning("å·²åˆªé™¤å…¨éƒ¨å„²å­˜å°è©±")
        st.rerun()
else:
    st.sidebar.info("ç›®å‰æ²’æœ‰å·²å„²å­˜çš„å°è©±")

if st.sidebar.button("ğŸ’¾ å„²å­˜ç›®å‰å°è©±", key="save_memory_now"):
    if st.session_state.get("messages"):
        save_memory(st.session_state.messages, mode)
        st.sidebar.success("å·²å°‡ç›®å‰å°è©±æ°¸ä¹…å„²å­˜åˆ°è³‡æ–™åº«")
        st.rerun()
    else:
        st.sidebar.warning("ç›®å‰æ²’æœ‰å°è©±å¯ä»¥å„²å­˜")


# ===============================
# â­ RAG Reset
# ===============================
if not rag_files:
    st.session_state.doc_vectorstore = None
    st.session_state.docs_loaded = False


# ===============================
# RAG å»ºç´¢å¼•
# ===============================
if rag_files and embeddings:
    all_text = ""
    for f in rag_files:
        raw = f.read()
        ext = f.name.split(".")[-1].lower()
        if ext in ["txt", "md"]:
            content = raw.decode("utf-8", errors="ignore")
        elif ext == "pdf":
            content = extract_pdf(raw)
        elif ext == "docx":
            content = extract_docx(raw)
        else:
            content = ""
        all_text += f"\n\n[æª”å:{f.name}]\n{content}"

    splitter = RecursiveCharacterTextSplitter(
        chunk_size=800,
        chunk_overlap=150,
    )
    docs = splitter.create_documents([all_text])
    st.session_state.doc_vectorstore = FAISS.from_documents(docs, embeddings)
    st.session_state.docs_loaded = True


# ===============================
# Sidebar ç‹€æ…‹é¡¯ç¤º
# ===============================
if st.session_state.docs_loaded:
    st.sidebar.success("ğŸ“š æ•™ææ¨¡å¼å•Ÿç”¨ä¸­")
else:
    st.sidebar.info("ğŸ¤– ä½¿ç”¨æ¨¡å‹æœ¬èº«çŸ¥è­˜å›ç­”")

if st.sidebar.button("ğŸ—‘ï¸ æ¸…é™¤ä¸Šå‚³è³‡æ–™"):
    st.session_state.doc_vectorstore = None
    st.session_state.docs_loaded = False
    st.sidebar.success("è³‡æ–™å·²æ¸…é™¤")


# ===============================
# å¦‚æœæ²’æœ‰ API key æˆ–æ²’æœ‰æ¨¡å‹ï¼Œç›´æ¥åœæ­¢
# ===============================
if not user_api_key or not model:
    st.stop()


# ===============================
# 7. Chat history
# ===============================
for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        for p in m["parts"]:
            if isinstance(p, str):
                st.markdown(p)
            else:
                st.image(p, use_container_width=True)


# ===============================
# 8. Input rowï¼ˆEnter ä¸é€å‡ºï¼‰
# ===============================
c1, c2 = st.columns([1, 1])

with c1:
    if st.button("ğŸ–¼ï¸", key=f"img_{st.session_state.upload_counter}"):
        st.session_state.show_image_uploader = True

with c2:
    mic = mic_recorder(
        start_prompt="ğŸ™ï¸",
        stop_prompt="â¹ï¸",
        just_once=True,
        key=f"mic_{st.session_state.upload_counter}",
    )

if st.session_state.show_image_uploader:
    img = st.file_uploader(
        "",
        type=["png", "jpg", "jpeg"],
        label_visibility="collapsed",
        key=f"imgf_{st.session_state.upload_counter}",
    )
    if img:
        st.session_state.uploaded_image = Image.open(img)
        st.session_state.show_image_uploader = False


def on_send():
    text = st.session_state.get("multi_enter_input", "").strip()
    if text:
        st.session_state["last_submitted_text"] = text
    st.session_state["multi_enter_input"] = ""


user_text = st.text_area(
    "è¼¸å…¥å•é¡Œâ€¦ï¼ˆEnter æ›è¡Œï¼ŒæŒ‰ä¸‹æ–¹æŒ‰éˆ•é€å‡ºï¼‰",
    key="multi_enter_input",
    height=80,
)

st.button("é€å‡º", on_click=on_send)

prompt = st.session_state.pop("last_submitted_text", None)


# ===============================
# 9. STT
# ===============================
if mic and mic.get("bytes") and client:
    audio = types.Part(
        inline_data=types.Blob(
            mime_type="audio/mp4",
            data=mic["bytes"],
        )
    )
    res = client.models.generate_content(
        model="gemini-2.5-flash",
        contents=[
            types.Content(
                role="user",
                parts=[types.Part(text="è½‰æˆç¹é«”ä¸­æ–‡"), audio],
            )
        ],
    )
    st.session_state.speech_buffer = res.text

final_prompt = st.session_state.speech_buffer or prompt
st.session_state.speech_buffer = None


# ===============================
# 10. Gemini å›ç­”ï¼ˆå«è¨˜æ†¶ï¼‰
# ===============================
if final_prompt and model:

    instruction = {
        "ä¸€èˆ¬èŠå¤©": "è«‹æ­£å¸¸å›ç­”å•é¡Œã€‚",
        "è§£é‡‹/è¬›è§£": "è«‹ç”¨ç™½è©±ä¸€æ­¥ä¸€æ­¥è§£é‡‹ã€‚",
        "é‡é»æ•´ç†": "æ•´ç† 3ï½7 å€‹é‡é»æ¢åˆ—ã€‚",
        "å‡ºå°æ¸¬é©—": "å‡º 5 é¡Œé¸æ“‡é¡Œï¼Œé™„ç­”æ¡ˆèˆ‡è§£é‡‹ã€‚",
    }[mode]

    context = ""
    if st.session_state.doc_vectorstore:
        docs = st.session_state.doc_vectorstore.as_retriever(k=6).invoke(final_prompt)
        context = "\n\n".join(d.page_content for d in docs)

    full_prompt = f"""
{instruction}

ã€æ•™æå…§å®¹ï¼ˆè‹¥æœ‰ï¼‰ã€‘
{context}

ã€ä½¿ç”¨è€…å•é¡Œã€‘
{final_prompt}
"""

    if st.session_state.uploaded_image:
        current_message = HumanMessage(
            content=[
                {
                    "type": "image_url",
                    "image_url": {
                        "url": encode_image(st.session_state.uploaded_image)
                    },
                },
                {"type": "text", "text": full_prompt},
            ]
        )
    else:
        current_message = HumanMessage(content=full_prompt)

    msgs = build_chat_history(
        st.session_state.messages,
        current_message
    )

    with st.chat_message("assistant"):
        with st.spinner("ğŸ¤– Gemini æ€è€ƒä¸­..."):
            answer = model.invoke(msgs).content
        st.markdown(answer)

    with st.chat_message("user"):
        if st.session_state.uploaded_image:
            st.image(st.session_state.uploaded_image)
        st.markdown(final_prompt)

    st.session_state.messages += [
        {"role": "user", "parts": [final_prompt]},
        {"role": "assistant", "parts": [answer]},
    ]

    st.session_state.uploaded_image = None
    st.session_state.upload_counter += 1
